{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tubes_ann.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMLskLJRXoA5TnjUFM9ejIE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maqmal/Machine-Learning/blob/main/tubes_ann.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdxpVdpRNUF-"
      },
      "source": [
        "import numpy as np \r\n",
        "import pandas as pd \r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from sklearn.preprocessing import StandardScaler\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.metrics import f1_score\r\n",
        "# %matplotlib inline"
      ],
      "execution_count": 460,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWT0zIKPOFsf"
      },
      "source": [
        "df = pd.read_csv('/content/Clean_data.csv')\r\n",
        "df = df.drop(df.columns[0], axis=1) # Drop kolom index\r\n",
        "\r\n",
        "# Memisah label dari feature untuk split data\r\n",
        "label_y = df['Exited']\r\n",
        "feature = df.drop(columns=['Exited'], axis=1)\r\n",
        "\r\n",
        "# Pisahkan data test dan data train\r\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(feature, label_y, train_size=0.60)\r\n",
        "\r\n",
        "# Normalisasi data menggunakan standard scaler\r\n",
        "X_train = StandardScaler().fit_transform(X_train)\r\n",
        "X_test = StandardScaler().fit_transform(X_test)\r\n",
        "\r\n",
        "Y_train = Y_train.to_numpy()\r\n",
        "Y_test = Y_test.to_numpy()\r\n"
      ],
      "execution_count": 461,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8gTN3hJdiFs"
      },
      "source": [
        "class ANN:\r\n",
        "  def __init__(self, layers, learning_rate, epoch, bias):\r\n",
        "    self.layers = layers\r\n",
        "    self.learning_rate = learning_rate\r\n",
        "    self.epoch = epoch\r\n",
        "    self.networks = {}\r\n",
        "    self.error_list = []\r\n",
        "    self.data_x = None\r\n",
        "    self.data_y = None\r\n",
        "    self.bias = bias\r\n",
        "\r\n",
        "  def sigmoid(self, x):\r\n",
        "    return 1/(1+np.exp(-x))\r\n",
        "\r\n",
        "  def sigmoid_der(self, x):\r\n",
        "    return self.sigmoid(x)*(1-self.sigmoid(x))\r\n",
        "\r\n",
        "  def set_weight(self):\r\n",
        "    np.random.seed(1)\r\n",
        "    self.networks['w1'] = np.random.rand(self.layers[0],self.layers[1])\r\n",
        "    self.networks['b1'] = self.bias \r\n",
        "    self.networks['w2'] = np.random.rand(self.layers[1],self.layers[2])\r\n",
        "    self.networks['b2'] = self.bias \r\n",
        "    self.networks['w3'] = np.random.rand(self.layers[2],self.layers[3])\r\n",
        "    self.networks['b3'] = self.bias \r\n",
        "\r\n",
        "  def fit(self, x, y):\r\n",
        "    self.data_x = x\r\n",
        "    self.data_y = y\r\n",
        "\r\n",
        "    self.set_weight()\r\n",
        "\r\n",
        "    for i in range(self.epoch):\r\n",
        "\r\n",
        "      V1 = np.dot(self.data_x, self.networks['w1']) + self.networks['b1']\r\n",
        "      A1 = self.sigmoid(V1)\r\n",
        "\r\n",
        "      V2 = np.dot(A1, self.networks['w2']) + self.networks['b2']\r\n",
        "      A2 = self.sigmoid(V2)\r\n",
        "\r\n",
        "      V3 = np.dot(A2, self.networks['w3']) + self.networks['b3']\r\n",
        "      A3 = self.sigmoid(V3)\r\n",
        "\r\n",
        "      E = self.data_y.reshape(6000,1) - A3\r\n",
        "  \r\n",
        "      MSE = (np.power(E,2).sum())/len(self.data_x)\r\n",
        "      print(MSE)\r\n",
        "      self.error_list.append(MSE)  \r\n",
        "\r\n",
        "      der_A3 = self.sigmoid_der(A3)\r\n",
        "      D3 =  der_A3 * E\r\n",
        "      dW3 = A2.T.dot(D3)\r\n",
        "\r\n",
        "      der_A2 = self.sigmoid_der(A2)\r\n",
        "      D2 =  der_A2 * D3.dot(self.networks['w3'].T)\r\n",
        "      dW2 = A1.T.dot(D2)\r\n",
        "\r\n",
        "      der_A1 = self.sigmoid_der(A1)\r\n",
        "      D1 = der_A1 * D2.dot(self.networks['w2'].T)\r\n",
        "      dW1 = self.data_x.T.dot(D1)\r\n",
        "\r\n",
        "      self.networks['w1'] += dW1 * self.learning_rate\r\n",
        "      self.networks['w2'] += dW2 * self.learning_rate\r\n",
        "      self.networks['w3'] += dW3 * self.learning_rate\r\n",
        "\r\n",
        "\r\n",
        "  def predict(self, X):\r\n",
        "    V1 = X.dot(self.networks['w1']) + self.networks['b1']\r\n",
        "    A1 = self.sigmoid(V1)\r\n",
        "\r\n",
        "    V2 = V1.dot(self.networks['w2']) + self.networks['b2']\r\n",
        "    A2 = self.sigmoid(V2)\r\n",
        "\r\n",
        "    V3 = V2.dot(self.networks['w3']) + self.networks['b3']\r\n",
        "    A3 = self.sigmoid(V3)\r\n",
        "\r\n",
        "    # for i in A3:\r\n",
        "    #   print(i)\r\n",
        "  \r\n",
        "    return np.round(A3)\r\n",
        "\r\n",
        "  def akurasi(self, y_actual, y_pred):\r\n",
        "        akurasi = int(sum(y_actual == y_pred) / len(y_actual) * 100)\r\n",
        "        return akurasi\r\n",
        "\r\n",
        "\r\n",
        "  def plot_loss(self):\r\n",
        "    # print(self.error_list)\r\n",
        "    plt.plot(self.error_list)\r\n",
        "    plt.xlabel(\"Iteration\")\r\n",
        "    plt.ylabel(\"Error\")\r\n",
        "    plt.title(\"Error curve for training\")\r\n",
        "    # plt.show()  \r\n",
        "\r\n"
      ],
      "execution_count": 462,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASNzcym8L6lp"
      },
      "source": [
        "artificial_neural_network = ANN(layers=[17,8,6,1], learning_rate=0.005, epoch=100, bias=0.45)\r\n",
        "artificial_neural_network.fit(X_train,Y_train)\r\n",
        "artificial_neural_network.plot_loss()\r\n",
        "\r\n",
        "train_pred = artificial_neural_network.predict(X_train)\r\n",
        "test_pred = artificial_neural_network.predict(X_test)\r\n",
        "\r\n",
        "train_pred = [int(i) for i in train_pred]\r\n",
        "test_pred = [int(i) for i in test_pred]\r\n",
        "\r\n",
        "# for i in range(len(test_pred)):\r\n",
        "#   print(\"Data ke-{} = {}\".format(i,test_pred[i]))\r\n",
        "\r\n",
        "print(\"Akurasi Data Training {}\".format(round(artificial_neural_network.akurasi(Y_train, train_pred),1)))\r\n",
        "print(\"Akurasi Data Test {}\".format(round(artificial_neural_network.akurasi(Y_test, test_pred),1)))\r\n",
        "F1 = round(f1_score(Y_test, test_pred, average='weighted'),2)*100\r\n",
        "print(\"F1-Score {}%\".format(F1))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}